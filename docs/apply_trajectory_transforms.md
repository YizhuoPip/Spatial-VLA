# apply_trajectory_transforms 

## å‡½æ•°ä½ç½®
`dataset/utils/rlds/dataset.py:212-308`

## å‡½æ•°ä½œç”¨
åœ¨è½¨è¿¹ï¼ˆtrajectoryï¼‰çº§åˆ«å¯¹æ•°æ®é›†è¿›è¡Œè½¬æ¢å’Œé‡æ ‡è®°ã€‚è¿™äº›è½¬æ¢éœ€è¦è®¿é—®æ•´ä¸ªè½¨è¿¹çš„æ•°æ®ï¼Œä½†ä¸æ¶‰åŠCPUå¯†é›†å‹æ“ä½œï¼ˆå¦‚å›¾åƒè§£ç ï¼‰ï¼Œä¸»è¦æ˜¯æ•°æ®çš„ç§»åŠ¨å’Œå¤åˆ¶ã€‚

---

## ğŸ“¥ è¾“å…¥æ•°æ®

### è¾“å…¥å‚æ•°ï¼š
```python
apply_trajectory_transforms(
    dataset: dl.DLataset,           # è¾“å…¥çš„è½¨è¿¹æ•°æ®é›†
    train: bool,                    # æ˜¯å¦ä¸ºè®­ç»ƒé›†
    goal_relabeling_strategy: str,  # ç›®æ ‡é‡æ ‡è®°ç­–ç•¥
    window_size: int = 1,           # è§‚æµ‹çª—å£å¤§å°
    future_action_window_size: int = 0,  # æœªæ¥åŠ¨ä½œçª—å£å¤§å°
    subsample_length: int = None,   # å­é‡‡æ ·é•¿åº¦
    skip_unlabeled: bool = False,   # æ˜¯å¦è·³è¿‡æ— æ ‡ç­¾æ•°æ®
    max_action: float = None,       # åŠ¨ä½œæœ€å¤§å€¼
    max_proprio: float = None,      # æœ¬ä½“æ„ŸçŸ¥æœ€å¤§å€¼
    task_augment_strategy: str = None,  # ä»»åŠ¡å¢å¼ºç­–ç•¥
    ...
)
```

### è¾“å…¥æ•°æ®æ ¼å¼ï¼ˆå•æ¡è½¨è¿¹ï¼‰ï¼š
```python
{
    'observation': {
        'image_primary': tf.Tensor([T, H, W, 3], dtype=string),  # Tä¸ªæ—¶é—´æ­¥çš„ç¼–ç å›¾åƒ
        'image_wrist': tf.Tensor([T, H, W, 3], dtype=string),    # Tä¸ªæ—¶é—´æ­¥çš„æ‰‹è…•å›¾åƒ
        'proprio': tf.Tensor([T, proprio_dim], dtype=float32),   # Tä¸ªæ—¶é—´æ­¥çš„æœ¬ä½“æ„ŸçŸ¥
        'timestep': tf.Tensor([T], dtype=int32),                 # æ—¶é—´æ­¥ç´¢å¼•
    },
    'action': tf.Tensor([T, action_dim], dtype=float32),         # Tä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œ
    'task': {
        'language_instruction': tf.Tensor([T], dtype=string),    # Tä¸ªè¯­è¨€æŒ‡ä»¤ï¼ˆé€šå¸¸ç›¸åŒï¼‰
    },
    'dataset_name': tf.Tensor([T], dtype=string),                # æ•°æ®é›†åç§°
    'absolute_action_mask': tf.Tensor([T, action_dim], dtype=bool),  # ç»å¯¹åŠ¨ä½œæ©ç 
}
```
å…¶ä¸­ `T` æ˜¯è½¨è¿¹é•¿åº¦ï¼ˆä¾‹å¦‚ 100 æ­¥ï¼‰

---

## ğŸ”„ å¤„ç†æµç¨‹è¯¦è§£

### æ­¥éª¤ 1: è¿‡æ»¤ï¼ˆFilteringï¼‰ã€ç¬¬ 258-268 è¡Œã€‘

#### 1.1 è·³è¿‡æ— æ ‡ç­¾æ•°æ®
```python
if skip_unlabeled:
    dataset = dataset.filter(
        lambda x: tf.math.reduce_any(x["task"]["language_instruction"] != "")
    )
```
**ä½œç”¨**ï¼šç§»é™¤æ²¡æœ‰è¯­è¨€æŒ‡ä»¤çš„è½¨è¿¹

**ç¤ºä¾‹**ï¼š
- è¾“å…¥è½¨è¿¹ A: language_instruction = "pick up the cup"  âœ… ä¿ç•™
- è¾“å…¥è½¨è¿¹ B: language_instruction = ""                âŒ ç§»é™¤

#### 1.2 è¿‡æ»¤å¼‚å¸¸åŠ¨ä½œ
```python
if max_action is not None:
    dataset = dataset.filter(
        lambda x: tf.math.reduce_all(tf.math.abs(x["action"]) <= max_action)
    )
```
**ä½œç”¨**ï¼šç§»é™¤åŠ¨ä½œå€¼è¶…è¿‡é˜ˆå€¼çš„è½¨è¿¹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯æ•°æ®ï¼‰

**ç¤ºä¾‹**ï¼šmax_action = 1.0
- è½¨è¿¹ A: actions = [0.5, -0.8, 0.3]  âœ… ä¿ç•™
- è½¨è¿¹ B: actions = [0.5, 1.5, 0.3]   âŒ ç§»é™¤ï¼ˆ1.5 > 1.0ï¼‰

### æ­¥éª¤ 2: æ·»åŠ å¡«å……æ©ç ï¼ˆAdd Padding Maskï¼‰ã€ç¬¬ 271 è¡Œã€‘

```python
dataset = dataset.traj_map(traj_transforms.add_pad_mask_dict, num_parallel_calls)
```

**ä½œç”¨**ï¼šä¸ºæ¯ä¸ªè§‚æµ‹å’Œä»»åŠ¡å­—æ®µæ·»åŠ æ©ç ï¼Œæ ‡è®°å“ªäº›æ˜¯çœŸå®æ•°æ®ï¼Œå“ªäº›æ˜¯å¡«å……æ•°æ®

**è½¬æ¢åçš„æ•°æ®**ï¼š
```python
{
    'observation': {
        'image_primary': ...,
        'pad_mask_dict': {
            'image_primary': tf.Tensor([T], dtype=bool),  # [True, True, ..., True]
            'proprio': tf.Tensor([T], dtype=bool),
        }
    },
    'task': {
        'language_instruction': ...,
        'pad_mask_dict': {
            'language_instruction': tf.Tensor([T], dtype=bool),
        }
    },
    ...
}
```

### æ­¥éª¤ 3: ç›®æ ‡é‡æ ‡è®°ï¼ˆGoal Relabelingï¼‰ã€ç¬¬ 274-278 è¡Œã€‘

```python
if goal_relabeling_strategy is not None:
    dataset = dataset.traj_map(
        partial(getattr(goal_relabeling, goal_relabeling_strategy), **goal_relabeling_kwargs),
        num_parallel_calls,
    )
```

**ä½œç”¨**ï¼šä¸ºè½¨è¿¹çš„æ¯ä¸ªæ—¶é—´æ­¥æ·»åŠ ç›®æ ‡ä¿¡æ¯ï¼ˆgoalï¼‰

**å¸¸ç”¨ç­–ç•¥**ï¼š
- `"uniform"`: ä»å½“å‰æ—¶é—´æ­¥åˆ°è½¨è¿¹ç»“æŸéšæœºé€‰æ‹©ä¸€ä¸ªæœªæ¥çŠ¶æ€ä½œä¸ºç›®æ ‡
- `"last"`: ä½¿ç”¨è½¨è¿¹æœ€åä¸€å¸§ä½œä¸ºç›®æ ‡

**ç¤ºä¾‹**ï¼ˆuniformç­–ç•¥ï¼‰ï¼š
```python
# åŸå§‹è½¨è¿¹ï¼ˆT=5æ­¥ï¼‰
timestep:  0     1     2     3     4
state:    [s0]  [s1]  [s2]  [s3]  [s4]

# é‡æ ‡è®°åï¼ˆæ·»åŠ goal_imageç­‰ï¼‰
timestep:  0     1     2     3     4
state:    [s0]  [s1]  [s2]  [s3]  [s4]
goal:     [s3]  [s4]  [s4]  [s4]  [s4]  # éšæœºä»æœªæ¥é€‰æ‹©
```

### æ­¥éª¤ 4: ä»»åŠ¡å¢å¼ºï¼ˆTask Augmentationï¼‰ã€ç¬¬ 281-289 è¡Œã€‘

```python
if train and task_augment_strategy is not None:
    dataset = dataset.traj_map(
        partial(getattr(task_augmentation, task_augment_strategy), **task_augment_kwargs),
        num_parallel_calls,
    )
```

**ä½œç”¨**ï¼šå¢å¼ºä»»åŠ¡æè¿°çš„å¤šæ ·æ€§ï¼ˆä»…åœ¨è®­ç»ƒæ—¶ï¼‰

**ç¤ºä¾‹ç­–ç•¥**ï¼š
- éšæœºæ›¿æ¢è¯­è¨€æŒ‡ä»¤çš„åŒä¹‰è¯
- éšæœºä¸¢å¼ƒæŸäº›ä»»åŠ¡æè¿°å­—æ®µ

### æ­¥éª¤ 5: åŠ¨ä½œå’Œè§‚æµ‹åˆ†å—ï¼ˆChunkingï¼‰ã€ç¬¬ 293-300 è¡Œã€‘â­ï¸ **æ ¸å¿ƒæ­¥éª¤**

```python
dataset = dataset.traj_map(
    partial(
        traj_transforms.chunk_act_obs,
        window_size=window_size,
        future_action_window_size=future_action_window_size,
    ),
    num_parallel_calls,
)
```

è¿™æ˜¯**æœ€é‡è¦çš„ä¸€æ­¥**ï¼è®©æˆ‘è¯¦ç»†è§£é‡Šï¼š

#### ä»€ä¹ˆæ˜¯åˆ†å—ï¼ˆChunkingï¼‰ï¼Ÿ

**ç›®çš„**ï¼š
1. ä¸ºæ¨¡å‹æä¾›å†å²è§‚æµ‹ä¸Šä¸‹æ–‡ï¼ˆè¿‡å»çš„å›¾åƒï¼‰
2. ä¸ºæ¨¡å‹æä¾›åŠ¨ä½œåºåˆ—ï¼ˆaction chunkingï¼‰ç”¨äºé¢„æµ‹æœªæ¥å¤šæ­¥åŠ¨ä½œ

**å‚æ•°è¯´æ˜**ï¼š
- `window_size=1`: è§‚æµ‹çª—å£å¤§å°ï¼ˆå½“å‰è§‚æµ‹ï¼‰
- `future_action_window_size=7`: æœªæ¥åŠ¨ä½œçª—å£å¤§å°ï¼ˆé¢„æµ‹æœªæ¥7æ­¥ï¼‰

#### è¯¦ç»†ç¤ºä¾‹ï¼š

å‡è®¾åŸå§‹è½¨è¿¹æœ‰ 5 ä¸ªæ—¶é—´æ­¥ï¼š

```python
# è¾“å…¥ï¼ˆåŸå§‹è½¨è¿¹ï¼‰
{
    'observation': {
        'image_primary': [img_0, img_1, img_2, img_3, img_4],  # shape: [5, H, W, 3]
    },
    'action': [a0, a1, a2, a3, a4],  # shape: [5, 7]
}

# ä½¿ç”¨ window_size=2, future_action_window_size=2 è¿›è¡Œåˆ†å—
```

**åˆ†å—ç´¢å¼•è®¡ç®—**ï¼š

å¯¹äºè§‚æµ‹ï¼ˆwindow_size=2ï¼‰ï¼š
```
timestep 0:  å– [img_0, img_0]  (ç¬¬ä¸€ä¸ªæ˜¯paddingï¼Œå› ä¸ºæ²¡æœ‰-1æ­¥)
timestep 1:  å– [img_0, img_1]
timestep 2:  å– [img_1, img_2]
timestep 3:  å– [img_2, img_3]  â† æœ€åä¸€ä¸ªæœ‰æ•ˆtimestep
# timestep 4 ä¸è¾“å‡ºï¼Œå› ä¸ºæ²¡æœ‰è¶³å¤Ÿçš„future actions
```

å¯¹äºåŠ¨ä½œï¼ˆwindow_size=2, future=2ï¼‰ï¼š
```
timestep 0:  å– [a0, a0, a1, a2]  (è¿‡å»1æ­¥ + å½“å‰ + æœªæ¥2æ­¥)
timestep 1:  å– [a0, a1, a2, a3]
timestep 2:  å– [a1, a2, a3, a4]
timestep 3:  å– [a2, a3, a4, a4]  (æœ€åä¸€ä¸ªactioné‡å¤)
```

**è¾“å‡ºæ•°æ®ç»“æ„**ï¼š
```python
{
    'observation': {
        'image_primary': [
            [img_0, img_0],  # timestep 0
            [img_0, img_1],  # timestep 1
            [img_1, img_2],  # timestep 2
            [img_2, img_3],  # timestep 3
        ],  # shape: [4, 2, H, W, 3]
        'pad_mask': [
            [False, True],   # timestep 0: ç¬¬ä¸€ä¸ªæ˜¯padding
            [True, True],    # timestep 1
            [True, True],    # timestep 2
            [True, True],    # timestep 3
        ],  # shape: [4, 2]
    },
    'action': [
        [a0, a0, a1, a2],  # timestep 0
        [a0, a1, a2, a3],  # timestep 1
        [a1, a2, a3, a4],  # timestep 2
        [a2, a3, a4, a4],  # timestep 3
    ],  # shape: [4, 4, 7]
}
```

**å…³é”®å˜åŒ–**ï¼š
1. è½¨è¿¹é•¿åº¦ä» 5 å˜æˆ 4ï¼ˆå‡å°‘ future_action_window_sizeï¼‰
2. observation å¢åŠ ä¸€ä¸ªç»´åº¦ï¼š`[T, H, W, 3]` â†’ `[T', window_size, H, W, 3]`
3. action å¢åŠ ä¸€ä¸ªç»´åº¦ï¼š`[T, action_dim]` â†’ `[T', window_size+future, action_dim]`

#### çœŸå®è®­ç»ƒåœºæ™¯ï¼ˆOpenVLAï¼‰ï¼š

```python
# é…ç½®
window_size = 1
future_action_window_size = 7  # NUM_ACTIONS_CHUNK - 1

# è¾“å…¥è½¨è¿¹é•¿åº¦ï¼šT = 100
# è¾“å‡ºè½¨è¿¹é•¿åº¦ï¼šT' = 100 - 7 = 93

# å¯¹äºæ¯ä¸ªtimestep t (0 <= t < 93)ï¼š
observation[t] = [image[t]]        # shape: [1, H, W, 3]
action[t] = [a[t], a[t+1], ..., a[t+7]]  # shape: [8, 7] - é¢„æµ‹å½“å‰+æœªæ¥7æ­¥
```

### æ­¥éª¤ 6: å­é‡‡æ ·ï¼ˆSubsamplingï¼‰ã€ç¬¬ 302-306 è¡Œã€‘

```python
if train and subsample_length is not None:
    dataset = dataset.traj_map(
        partial(traj_transforms.subsample, subsample_length=subsample_length),
        num_parallel_calls,
    )
```

**ä½œç”¨**ï¼šéšæœºé‡‡æ ·è½¨è¿¹ä¸­çš„éƒ¨åˆ†æ—¶é—´æ­¥ï¼Œç¼©çŸ­è½¨è¿¹é•¿åº¦

**ç¤ºä¾‹**ï¼šsubsample_length=50
```python
# è¾“å…¥ï¼š93ä¸ªåˆ†å—åçš„æ—¶é—´æ­¥
# è¾“å‡ºï¼šéšæœºé€‰æ‹©50ä¸ªæ—¶é—´æ­¥
indices = random_shuffle([0, 1, 2, ..., 92])[:50]
traj = gather(traj, indices)
```

---

## ğŸ“¤ è¾“å‡ºæ•°æ®

### æœ€ç»ˆè¾“å‡ºæ ¼å¼ï¼š

```python
{
    'observation': {
        'image_primary': tf.Tensor([T', window_size, H, W, 3], dtype=string),
        'image_wrist': tf.Tensor([T', window_size, H, W, 3], dtype=string),
        'proprio': tf.Tensor([T', window_size, proprio_dim], dtype=float32),
        'pad_mask': tf.Tensor([T', window_size], dtype=bool),
        'pad_mask_dict': {...},
    },
    'action': tf.Tensor([T', window_size+future, action_dim], dtype=float32),
    'task': {
        'language_instruction': tf.Tensor([T'], dtype=string),
        'goal_image': tf.Tensor([T', H, W, 3], dtype=string),  # å¦‚æœæœ‰goal relabeling
        'pad_mask_dict': {...},
    },
    'dataset_name': tf.Tensor([T'], dtype=string),
}
```

å…¶ä¸­ï¼š
- `T' = T - future_action_window_size`ï¼ˆå¦‚æœæ²¡æœ‰subsampleï¼‰
- æ¯ä¸ªobservationå’Œactionéƒ½å¸¦æœ‰æ—¶é—´çª—å£ç»´åº¦

---

## ğŸ¯ å®é™…åº”ç”¨ç¤ºä¾‹

### OpenVLA é…ç½®ï¼š

```python
traj_transform_kwargs = dict(
    window_size=1,                      # åªä½¿ç”¨å½“å‰è§‚æµ‹
    future_action_window_size=7,        # é¢„æµ‹8æ­¥åŠ¨ä½œï¼ˆå½“å‰+æœªæ¥7æ­¥ï¼‰
    skip_unlabeled=True,                # è·³è¿‡æ— æ ‡ç­¾æ•°æ®
    goal_relabeling_strategy="uniform", # ä½¿ç”¨uniformç­–ç•¥æ·»åŠ goal
)

# è¾“å…¥ï¼šä¸€æ¡100æ­¥çš„è½¨è¿¹
# è¾“å‡ºï¼š93ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
#   - 1ä¸ªå½“å‰è§‚æµ‹
#   - 8ä¸ªè¿ç»­åŠ¨ä½œï¼ˆç”¨äºaction chunkingï¼‰
#   - 1ä¸ªgoalå›¾åƒ
#   - 1ä¸ªè¯­è¨€æŒ‡ä»¤
```

### æ•°æ®æµç¤ºæ„å›¾ï¼š

```
åŸå§‹è½¨è¿¹ (T=100æ­¥)
    â†“
[è¿‡æ»¤] ç§»é™¤æ— æ•ˆæ•°æ®
    â†“
[æ·»åŠ pad_mask] æ ‡è®°å¡«å……æ•°æ®
    â†“
[goal relabeling] æ·»åŠ ç›®æ ‡ä¿¡æ¯
    â†“
[chunking] â­ï¸ å…³é”®æ­¥éª¤
    â†’ è§‚æµ‹: [100, H, W, 3] â†’ [93, 1, H, W, 3]
    â†’ åŠ¨ä½œ: [100, 7] â†’ [93, 8, 7]
    â†“
[subsampling] å¯é€‰çš„é•¿åº¦æˆªæ–­
    â†“
è¾“å‡º (T'=93ä¸ªè®­ç»ƒæ ·æœ¬)
```

---

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

1. **è¾“å…¥**ï¼šå®Œæ•´çš„æœºå™¨äººè½¨è¿¹ï¼ˆTä¸ªæ—¶é—´æ­¥ï¼‰
2. **æ ¸å¿ƒè½¬æ¢**ï¼šchunkingï¼ˆåˆ†å—ï¼‰ï¼Œå°†åºåˆ—æ•°æ®è½¬æ¢ä¸ºå¸¦æ—¶é—´çª—å£çš„è®­ç»ƒæ ·æœ¬
3. **è¾“å‡º**ï¼šT' ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œæ¯ä¸ªåŒ…å«è§‚æµ‹çª—å£å’ŒåŠ¨ä½œåºåˆ—
4. **é•¿åº¦å˜åŒ–**ï¼šT â†’ T' = T - future_action_window_size
5. **ç»´åº¦å¢åŠ **ï¼šæ‰€æœ‰æ—¶é—´åºåˆ—æ•°æ®éƒ½å¢åŠ ä¸€ä¸ªçª—å£ç»´åº¦

è¿™ä¸ªå‡½æ•°æ˜¯è®­ç»ƒ VLA æ¨¡å‹çš„å…³é”®é¢„å¤„ç†æ­¥éª¤ï¼Œå®ƒå°†åŸå§‹è½¨è¿¹æ•°æ®è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹è®­ç»ƒçš„æ ¼å¼ï¼
